{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Azure AI Agents with Action Tools**\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates how to create and use AI agents with action tools in Azure AI Foundry. You'll learn how to enhance an AI agent's capabilities by integrating custom functions that can perform actions on behalf of the user, allowing the agent to interact with external systems and APIs.\n",
    "\n",
    "## What are Action Tools?\n",
    "Unlike knowledge tools that retrieve information (like Bing search in the previous notebook), action tools enable agents to perform specific functions and tasks:\n",
    "\n",
    "- **Custom Python Functions**: Define actions the agent can execute\n",
    "- **Tool Calling**: The agent determines when and how to use these functions\n",
    "- **Action Execution**: The application handles the actual function calls\n",
    "- **Response Integration**: Results from function calls are incorporated into agent responses\n",
    "\n",
    "This creates a powerful pattern where AI agents can interface with virtually any system or API through custom code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting Up the Environment\n",
    "\n",
    "First, we'll import the necessary libraries and load environment variables from a `.env` file.\n",
    "This provides access to our Azure AI Foundry project connection string and model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Azure AI Project Client\n",
    "\n",
    "Now we'll establish a connection to our Azure AI Foundry project using the connection string from our environment variables. This client will be used to manage agents, threads, and function tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Create an Azure AI Client from a connection string, copied from your Azure AI Foundry project.\n",
    "# It should be in the format \"<HostName>;<AzureSubscriptionId>;<ResourceGroup>;<HubName>\"\n",
    "# Customers need to login to Azure subscription via Azure CLI and set the environment variables\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    conn_str=os.environ[\"PROJECT_CONNECTION_STRING\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Defining Action Tools\n",
    "\n",
    "Action tools are custom Python functions that the agent can call to perform specific tasks. Here we'll define two functions:\n",
    "\n",
    "1. **fetch_weather**: Retrieves weather information for a specific location\n",
    "2. **check_network_status**: Provides telecommunications network status information\n",
    "\n",
    "These functions would typically connect to real APIs or databases, but for demonstration purposes, we'll use mock data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Any, Callable, Set, Optional\n",
    "    \n",
    "def fetch_weather(location: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches the weather information for the specified location.\n",
    "\n",
    "    :param location (str): The location to fetch weather for.\n",
    "    :return: Weather information as a JSON string.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    # Mock API response.\n",
    "    mock_weather_data = {\n",
    "        \"New York\": \"Sunny, 25°C\",\n",
    "        \"London\": \"Cloudy, 18°C\",\n",
    "        \"Tokyo\": \"Rainy, 22°C\",\n",
    "        \"Stockholm\": \"Snowy, -5°C\",\n",
    "    }\n",
    "    \n",
    "    weather = mock_weather_data.get(location, \"Weather data not available for this location.\")\n",
    "    weather_json = json.dumps({\"weather\": weather})\n",
    "    return weather_json\n",
    "\n",
    "def check_network_status(location: str, service_type: Optional[str] = None) -> str:\n",
    "    \"\"\"\n",
    "    Checks the status of telecommunications network in a specified location.\n",
    "    \n",
    "    :param location (str): The location to check network status for.\n",
    "    :param service_type (str, optional): Type of service to check (e.g., \"4G\", \"5G\", \"VoLTE\").\n",
    "                                         If not specified, returns status for all services.\n",
    "    :return: Network status information as a JSON string.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    # Mock network status data\n",
    "    network_data = {\n",
    "        \"Stockholm\": {\n",
    "            \"5G\": \"Operational - 98.7% coverage\",\n",
    "            \"4G\": \"Operational - 99.9% coverage\",\n",
    "            \"VoLTE\": \"Operational\"\n",
    "        },\n",
    "        \"Gothenburg\": {\n",
    "            \"5G\": \"Partial outage - 85.3% coverage\",\n",
    "            \"4G\": \"Operational - 99.5% coverage\",\n",
    "            \"VoLTE\": \"Operational\"\n",
    "        },\n",
    "        \"New York\": {\n",
    "            \"5G\": \"Operational - 92.1% coverage\",\n",
    "            \"4G\": \"Operational - 99.7% coverage\",\n",
    "            \"VoLTE\": \"Maintenance in progress\"\n",
    "        },\n",
    "        \"London\": {\n",
    "            \"5G\": \"Operational - 90.5% coverage\",\n",
    "            \"4G\": \"Operational - 99.8% coverage\",\n",
    "            \"VoLTE\": \"Operational\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Check if the location exists in our mock data\n",
    "    if location not in network_data:\n",
    "        return json.dumps({\"error\": \"Location not found in network database\"})\n",
    "    \n",
    "    # Return data for the specific service type if provided\n",
    "    if service_type:\n",
    "        if service_type in network_data[location]:\n",
    "            return json.dumps({\n",
    "                \"location\": location,\n",
    "                \"service\": service_type,\n",
    "                \"status\": network_data[location][service_type],\n",
    "                \"timestamp\": \"2025-04-04T10:30:00Z\"  # Using current date from context\n",
    "            })\n",
    "        else:\n",
    "            return json.dumps({\"error\": f\"Service type {service_type} not available in {location}\"})\n",
    "    \n",
    "    # Return all service data for the location\n",
    "    return json.dumps({\n",
    "        \"location\": location,\n",
    "        \"services\": network_data[location],\n",
    "        \"timestamp\": \"2025-04-04T10:30:00Z\"  # Using current date from context\n",
    "    })\n",
    "\n",
    "\n",
    "# Statically defined user functions for fast reference\n",
    "agent_functions: Set[Callable[..., Any]] = {\n",
    "    fetch_weather,\n",
    "    check_network_status\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defining Agent Instructions\n",
    "\n",
    "System instructions guide how the agent behaves and uses its tools. Here we create instructions that specify:\n",
    "- The agent's capabilities (weather information and network status)\n",
    "- When and how to use each of the available functions\n",
    "- How the agent should format and present information to users\n",
    "\n",
    "These instructions serve as the agent's \"operating manual\" for processing queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message=(\n",
    "    \"You are an assistant with access to both weather information and telecommunications network status data. \"\n",
    "    \"You can help with the following:\\n\"\n",
    "    \"1. Checking current weather conditions in various locations\\n\"\n",
    "    \"2. Providing network status information in different regions, including details about 4G, 5G, and VoLTE services\\n\\n\"\n",
    "    \"For network status, you can check overall network conditions in a location or get specific information about \"\n",
    "    \"a particular service like 5G coverage. Feel free to ask for clarification if the user's request is ambiguous.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating the Agent\n",
    "\n",
    "Now we'll create the actual agent with our system instructions and function tools. The agent combines:\n",
    "- A language model (specified in our environment variables)\n",
    "- Our system instructions\n",
    "- Access to the custom functions we defined earlier\n",
    "\n",
    "This creates a capable assistant that can perform actions on behalf of the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent, ID: asst_xSKyXK9sKSd2Ja0Lj9WMbEhE\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.projects.models import FunctionTool\n",
    "\n",
    "functions = FunctionTool(functions=agent_functions)\n",
    "\n",
    "agent = project_client.agents.create_agent(\n",
    "    name=\"my-action-tool-agent\",\n",
    "    model=os.getenv(\"chatModel\"),\n",
    "    instructions=system_message,\n",
    "    tools=functions.definitions,\n",
    ")\n",
    "\n",
    "print(f\"Created agent, ID: {agent.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating a Thread\n",
    "\n",
    "Threads are conversation containers in the Agent API. Each thread:\n",
    "- Holds the history of messages between user and agent\n",
    "- Maintains conversation state and context\n",
    "- Enables multi-turn conversations\n",
    "\n",
    "Think of a thread as a dedicated, persistent chat session for a specific conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = project_client.agents.create_thread()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Adding a Message to the Thread\n",
    "\n",
    "Now we'll add our first user message to the thread. This message will be processed by the agent when we run it.\n",
    "We're asking about 5G network status in Stockholm, which will require the agent to use the `check_network_status` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created message, ID: msg_0YNOEtyOAfUd2QjK1aOHn6ux\n"
     ]
    }
   ],
   "source": [
    "message = project_client.agents.create_message(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"How's the 5G network in Stockholm?\",\n",
    ")\n",
    "print(f\"Created message, ID: {message.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Running the Agent with Tool Execution\n",
    "\n",
    "This section demonstrates the core workflow for agents with action tools:\n",
    "\n",
    "1. **Create a Run**: Start the agent processing on our thread\n",
    "2. **Monitor Status**: Check if the agent needs to call functions\n",
    "3. **Execute Tool Calls**: When needed, run the appropriate function\n",
    "4. **Submit Tool Outputs**: Return the function results to the agent\n",
    "5. **Continue Processing**: Let the agent incorporate results into its response\n",
    "\n",
    "This orchestration pattern allows the agent to seamlessly interact with external systems and APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created run, ID: run_zgFLYGio4vxIZvOgDHAf87mn\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Executing tool call: {'id': 'call_gpYlo9aUiup6rL3jVCo5b6mO', 'type': 'function', 'function': {'name': 'check_network_status', 'arguments': '{\"location\":\"Stockholm\",\"service_type\":\"5G\"}'}}\n",
      "Tool outputs: [{'tool_call_id': 'call_gpYlo9aUiup6rL3jVCo5b6mO', 'output': '{\"location\": \"Stockholm\", \"service\": \"5G\", \"status\": \"Operational - 98.7% coverage\", \"timestamp\": \"2025-04-04T10:30:00Z\"}'}]\n",
      "Current run status: requires_action\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: completed\n",
      "Run completed with status: completed\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from azure.ai.projects.models import RequiredFunctionToolCall, SubmitToolOutputsAction, ToolOutput\n",
    "\n",
    "run = project_client.agents.create_run(thread_id=thread.id, agent_id=agent.id)\n",
    "print(f\"Created run, ID: {run.id}\")\n",
    "\n",
    "while run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n",
    "    run = project_client.agents.get_run(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "    if run.status == \"requires_action\" and isinstance(run.required_action, SubmitToolOutputsAction):\n",
    "        # When the status is requires_action, your code is responsible for calling the function tools.\n",
    "        tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
    "        if not tool_calls: # If no tool calls are provided, cancel the run.\n",
    "            print(\"No tool calls provided - cancelling run\")\n",
    "            project_client.agents.cancel_run(thread_id=thread.id, run_id=run.id)\n",
    "            break\n",
    "\n",
    "        tool_outputs = []\n",
    "        for tool_call in tool_calls:\n",
    "            if isinstance(tool_call, RequiredFunctionToolCall):\n",
    "                try:\n",
    "                    print(f\"Executing tool call: {tool_call}\")\n",
    "                    output = functions.execute(tool_call)\n",
    "                    # If the output is not a string, convert it to JSON string\n",
    "                    if not isinstance(output, str):\n",
    "                        output = json.dumps(output)\n",
    "                    tool_outputs.append(\n",
    "                        ToolOutput(\n",
    "                            tool_call_id=tool_call.id,\n",
    "                            output=output,\n",
    "                        )\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Error executing tool_call {tool_call.id}: {e}\")\n",
    "\n",
    "        print(f\"Tool outputs: {tool_outputs}\")\n",
    "        if tool_outputs:\n",
    "            project_client.agents.submit_tool_outputs_to_run(\n",
    "                thread_id=thread.id, run_id=run.id, tool_outputs=tool_outputs\n",
    "            )\n",
    "    print(f\"Current run status: {run.status}\")\n",
    "print(f\"Run completed with status: {run.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Thread Messages\n",
    "\n",
    "Now let's examine the conversation thread to see the agent's response. The `pretty_print_thread_messages` helper function formats the conversation in a readable way, showing both user queries and agent responses that incorporate information from the function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "👤 USER\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">How's the 5G network in Stockholm?                                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "How's the 5G network in Stockholm?                                                                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤖 ASSISTANT\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The 5G network in Stockholm is operational with a coverage of 98.7%.                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "The 5G network in Stockholm is operational with a coverage of 98.7%.                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.helper import pretty_print_thread_messages\n",
    "\n",
    "messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "pretty_print_thread_messages(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Continuing the Conversation\n",
    "\n",
    "Let's add a follow-up question to demonstrate how the agent maintains context across multiple turns. This time we'll ask about the weather in Stockholm, which will require the agent to use the `fetch_weather` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created message, ID: msg_EhMVEfOw6rN3DPu1j8QJ2djq\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message = project_client.agents.create_message(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"what's the weather?\",\n",
    ")\n",
    "print(f\"Created message, ID: {message.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Follow-up Question\n",
    "\n",
    "Now we'll run the agent again to process our follow-up question about the weather. The agent will:\n",
    "1. Understand the query is about weather rather than network status\n",
    "2. Use the appropriate `fetch_weather` function\n",
    "3. Incorporate the weather data into its response\n",
    "\n",
    "This demonstrates how an agent can intelligently select the right tool for each user request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created run, ID: run_AEtiK6WghiXXYtYI2qFuLdAt\n",
      "\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Executing tool call: {'id': 'call_tlDfVbffWsMauOqPV2kZ2apY', 'type': 'function', 'function': {'name': 'fetch_weather', 'arguments': '{\"location\":\"Stockholm\"}'}}\n",
      "Tool outputs: [{'tool_call_id': 'call_tlDfVbffWsMauOqPV2kZ2apY', 'output': '{\"weather\": \"Snowy, -5\\\\u00b0C\"}'}]\n",
      "Current run status: requires_action\n",
      "Current run status: queued\n",
      "Current run status: queued\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: completed\n",
      "Run completed with status: completed\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from azure.ai.projects.models import RequiredFunctionToolCall, SubmitToolOutputsAction, ToolOutput\n",
    "\n",
    "run = project_client.agents.create_run(thread_id=thread.id, agent_id=agent.id)\n",
    "print(f\"Created run, ID: {run.id}\")\n",
    "\n",
    "while run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n",
    "    run = project_client.agents.get_run(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "    if run.status == \"requires_action\" and isinstance(run.required_action, SubmitToolOutputsAction):\n",
    "        # When the status is requires_action, your code is responsible for calling the function tools.\n",
    "        tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
    "        if not tool_calls: # If no tool calls are provided, cancel the run.\n",
    "            print(\"No tool calls provided - cancelling run\")\n",
    "            project_client.agents.cancel_run(thread_id=thread.id, run_id=run.id)\n",
    "            break\n",
    "\n",
    "        tool_outputs = []\n",
    "        for tool_call in tool_calls:\n",
    "            if isinstance(tool_call, RequiredFunctionToolCall):\n",
    "                try:\n",
    "                    print(f\"Executing tool call: {tool_call}\")\n",
    "                    output = functions.execute(tool_call)\n",
    "                    # If the output is not a string, convert it to JSON string\n",
    "                    if not isinstance(output, str):\n",
    "                        output = json.dumps(output)\n",
    "                    tool_outputs.append(\n",
    "                        ToolOutput(\n",
    "                            tool_call_id=tool_call.id,\n",
    "                            output=output,\n",
    "                        )\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Error executing tool_call {tool_call.id}: {e}\")\n",
    "\n",
    "        print(f\"Tool outputs: {tool_outputs}\")\n",
    "        if tool_outputs:\n",
    "            project_client.agents.submit_tool_outputs_to_run(\n",
    "                thread_id=thread.id, run_id=run.id, tool_outputs=tool_outputs\n",
    "            )\n",
    "    print(f\"Current run status: {run.status}\")\n",
    "print(f\"Run completed with status: {run.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the Complete Conversation\n",
    "\n",
    "Let's see the full conversation thread, which now includes both our network status query and weather query, along with the agent's responses that incorporate data from the function calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "👤 USER\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">How's the 5G network in Stockholm?                                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "How's the 5G network in Stockholm?                                                                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤖 ASSISTANT\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The 5G network in Stockholm is operational with a coverage of 98.7%.                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "The 5G network in Stockholm is operational with a coverage of 98.7%.                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "👤 USER\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">what's the weather?                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "what's the weather?                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤖 ASSISTANT\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The weather in Stockholm is currently snowy, with a temperature of -5°C.                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "The weather in Stockholm is currently snowy, with a temperature of -5°C.                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.helper import pretty_print_thread_messages\n",
    "\n",
    "messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "pretty_print_thread_messages(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cleanup\n",
    "\n",
    "When we're finished with our agent and thread, it's good practice to clean up these resources. This helps manage resource usage and keeps your environment tidy.\n",
    "\n",
    "In a production environment, you might retain threads for longer periods to maintain conversation history, but for this demonstration we'll delete both the agent and thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted agent\n",
      "\n",
      "thread: thread_prL0KeyvYaZx0T3q3rIDdoTi deleted\n"
     ]
    }
   ],
   "source": [
    "# Delete the agent when done\n",
    "project_client.agents.delete_agent(agent.id)\n",
    "print(\"Deleted agent\")\n",
    "\n",
    "# Delete Thread when done\n",
    "project_client.agents.delete_thread(thread_id=thread.id)\n",
    "print(f\"thread: {thread.id} deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ericsson-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
